# 4DCBCT-NNet-Reconstruction 操作マニュアル（日本語版）

## プロジェクト概要
本プロジェクトは、深層学習ベースの4Dコーンビーム CT（CBCT）医用画像再構成システムを実装しており、訓練、推論、評価の3つの主要モジュールを含んでいます。

## コードファイル説明

### 1. 001_train.py - モデル訓練スクリプト
**機能説明**：N-net深層学習モデルの訓練を実装し、データロード、モデル訓練、検証、ログ記録を含みます。

#### 主要特徴
- 複数の学習率スケジューラーをサポート（StepLR、ReduceLROnPlateau、CosineAnnealingWarmRestartsなど）
- TensorBoardとWeights & Biasesのログ記録を統合
- MONAIライブラリの専門的な医用画像損失関数を使用
- 早期停止メカニズムを実装してオーバーフィッティングを防止
- 複数のデータ拡張技術をサポート

#### 使用方法
1. **パラメータ設定**
   - `config.py` で訓練パラメータを設定
   - データパス、モデルパラメータ、訓練設定を確認

2. **訓練実行**
   ```bash
   python 001_train.py
   ```

3. **出力ファイル**
   - 実験結果は `experiments/Nnet/{FOV_TYPE}/{TIMESTAMP}/` ディレクトリに保存
   - 最良モデル重み、設定ファイルバックアップ、TensorBoardログなどを含む

#### 重要な設定項目
- `TRAINING_CONFIG['epochs']`：訓練エポック数
- `TRAINING_CONFIG['train_batch_size']`：訓練バッチサイズ
- `SCHEDULER_CONFIG['type']`：学習率スケジューラータイプ
- `DATASET_CONFIG['data_root']`：データルートディレクトリ

### 2. 002_inference.py - モデル推論スクリプト
**機能説明**：訓練済みモデルを使用してテストデータに対して推論を実行し、修復された画像を生成して評価指標を計算します。

#### 主要特徴
- 訓練済みモデル重みの自動ロード
- 複数の画像品質評価指標を計算（PSNR、SSIM、MS-SSIM、Corr2）
- 比較画像を生成（Prior | Noisy | Restored | GT）
- PNGフォーマットとRAWフォーマットの結果画像を保存
- 統計レポートと可視化チャートを生成

#### 使用方法
1. **モデルパスの設定**
   - スクリプト内の `OUTPUT_FOLDER` 変数を修正し、訓練済みモデルディレクトリを指定
   ```python
   OUTPUT_FOLDER = '/path/to/your/trained/model/folder'
   ```

2. **⚠️ 重要な設定一貫性チェック**
   - `002_inference.py` の `OUTPUT_FOLDER` に対応するFOVタイプと `config.py` の `DATASET_CONFIG['test_fov_type']` 設定が一致している必要があります
   - **設定対応関係の例**：
     ```python
     # OUTPUT_FOLDER が FovL で訓練されたモデルを指している場合：
     OUTPUT_FOLDER = '.../20251018_NNet_FovL_phase_00'
     # config.py で以下を設定する必要があります：
     DATASET_CONFIG['test_fov_type'] = 'FovL'
     
     # OUTPUT_FOLDER が FovS_180 で訓練されたモデルを指している場合：
     OUTPUT_FOLDER = '.../20251016_NNet_FovS180_phase_00'
     # config.py で以下を設定する必要があります：
     DATASET_CONFIG['test_fov_type'] = 'FovS_180'
     
     # OUTPUT_FOLDER が FovS_360 で訓練されたモデルを指している場合：
     OUTPUT_FOLDER = '.../20251017_NNet_FovS360_phase_00'
     # config.py で以下を設定する必要があります：
     DATASET_CONFIG['test_fov_type'] = 'FovS_360'
     ```
   - **間違った設定は以下を引き起こします**：データロード失敗またはモデルとテストデータの不一致エラー

3. **推論実行**
   ```bash
   python 002_inference.py
   ```

4. **出力ファイル**
   - `inference_results/comparison_images/`：PNGフォーマット比較画像
   - `inference_results/comparison_raw_images/`：RAWフォーマット画像データ
   - `inference_results/evaluation_results/`：評価レポートと統計チャート

#### 重要指標説明
- **PSNR**：ピーク信号対雑音比、数値が高いほど画像品質が良い
- **SSIM**：構造類似性指数、範囲0-1、1に近いほど良い
- **MS-SSIM**：マルチスケール構造類似性指数
- **Corr2**：相関係数、画像間の線形相関性を測定
- **MAE**：平均絶対誤差、値が小さいほど良い
- **RMSE**：平方根平均二乗誤差、値が小さいほど良い

### 3. 101_evaluate_multi_infer_AllSubjects.py - 複数モデル比較評価スクリプト
**機能説明**：複数の推論結果に対して横断的比較評価を行い、複数の被験者のバッチ処理をサポートします。

#### 主要特徴
- 複数のモデル結果の同時比較をサポート
- 共通の被験者データを自動検出
- ラインプロファイル分析チャートを生成
- バイオリンプロットと散布図を作成して統計分析
- ROI領域定量評価をサポート

#### 使用方法
1. **評価パラメータの設定**
   - スクリプト内の `INFER_FOLDERS` 辞書を修正し、比較したいモデル結果パスを追加
   ```python
   INFER_FOLDERS = {
       'model_1': '/path/to/model1/inference_results/comparison_raw_images',
       'model_2': '/path/to/model2/inference_results/comparison_raw_images',
       # さらにモデルを追加...
   }
   ```

2. **評価パラメータの設定**
   - `IMG_NUM_RANGE`：評価する画像番号範囲
   - `ROI`：定量評価の関心領域
   - `LP_*`：ラインプロファイル分析パラメータ

3. **評価実行**
   ```bash
   python 101_evaluate_multi_infer_AllSubjects.py
   ```

4. **出力ファイル**
   - `VisualEvaluation/`：目視評価用の結合画像
   - `LineProfileEvaluation/`：ラインプロファイル分析結果
   - `QuantitativeEvaluation/`：定量評価レポートと統計チャート

## 詳細設定説明 (config.py)

システムのすべての重要パラメータは `config.py` ファイルで一元管理されています。以下は各設定モジュールの詳細説明です：

### TRAINING_CONFIG - 訓練設定パラメータ

```python
TRAINING_CONFIG = {
    'train_batch_size': 1,              # 訓練バッチサイズ、GPUメモリに応じて調整（1-8）
    'val_batch_size': 48,               # 検証バッチサイズ、大きな値に設定して検証を高速化
    'num_workers': 1,                   # データロードプロセス数、CPUコア数の1/2を推奨
    'epochs': 100,                      # 総訓練エポック数、通常50-200に設定
    'model_save_dir': './trained_model', # モデル保存ディレクトリ（相対パス）
    'weight_l1': 0.1,                   # L1損失重み、画像の詳細保持を制御
    'weight_percep': 0.2,               # 知覚損失重み、視覚品質を制御
    'weight_ssim': 0.3,                 # SSIM損失重み、構造類似性を制御
    'weight_mse': 0.4,                  # MSE損失重み、全体誤差を制御
    'seed': 42,                         # ランダムシード、実験の再現性を確保
    'early_stopping_patience': 3,       # 早期停止の忍耐値、検証損失が改善しないエポック数
}
```

### DATASET_CONFIG - データセット設定パラメータ

```python
DATASET_CONFIG = {
    'data_root': '/home/zzg/data/Medical/4D_Lung_CBCT_Hitachi/dataset/',  # データルートディレクトリの絶対パス
    'train_fov_type': 'FovS_360',       # 訓練データFOVタイプ："FovL", "FovS_180", "FovS_360"
    'test_fov_type': 'FovS_360',        # テストデータFOVタイプ
    'train_dataset_indices': list(range(0, 40)),    # 訓練データインデックス範囲
    'val_dataset_indices': list(range(40, 45)),     # 検証データインデックス範囲
    'test_dataset_indices': list(range(45, 50)),    # テストデータインデックス範囲
    'image_size': (512, 512),           # 画像サイズ、512x512に固定
    'image_number': 384,                # 各被験者の画像数
}
```

#### 重要設定説明：
- **data_root**：データセットの絶対パスを設定する必要があります
- **FOVタイプ**：
  - `FovL`：大視野（Large Field of View）
  - `FovS_180`：小視野180度
  - `FovS_360`：小視野360度
- **データ分割**：訓練、検証、テストデータは重複せず、すべての利用可能データをカバーする

### MODEL_CONFIG - モデル設定パラメータ

```python
MODEL_CONFIG = {
    'input_channels': 1,                # 入力チャンネル数、医用CT画像は通常1
    'output_channels': 1,               # 出力チャンネル数、再構成画像は1
}
```

### LOGGING_CONFIG - ログ設定パラメータ

```python
LOGGING_CONFIG = {
    'use_wandb': True,                  # Weights & Biasesオンラインログを使用するか
    'use_tensorboard': True,            # TensorBoardローカルログを使用するか
    'wandb_project': 'nnet-medical-ct', # W&Bプロジェクト名
    'wandb_entity': None,               # W&Bユーザー名またはチーム名（オプション）
}
```

#### 設定提案：
- **初回使用**：`use_tensorboard=True`, `use_wandb=False` を推奨
- **チーム協作**：W&B関連パラメータを設定して実験結果を共有
- **オフライン環境**：`use_wandb=False` に設定し、TensorBoardのみ使用

### SCHEDULER_CONFIG - 学習率スケジューラー設定

```python
SCHEDULER_CONFIG = {
    'type': 'ReduceLROnPlateau',        # スケジューラータイプ
    'step_size': 1,                     # StepLRステップサイズ
    'gamma': 0.90,                      # 学習率減衰係数
    'lr': 1e-4,                         # 初期学習率（廃止予定、max_lrを使用）
    'min_lr': 1e-6,                     # 最小学習率
    'max_lr': 1e-4,                     # 最大学習率
    # ReduceLROnPlateau 固有パラメータ
    'plateau_factor': 0.2,              # 検証損失停滞時の減衰係数
    'plateau_patience': 1,              # 検証損失改善を待つエポック数
    'ReduceLR_min_lr': 1e-7,           # ReduceLROnPlateauの最小学習率
    # CosineAnnealingWarmRestarts 固有パラメータ
    'T_0': 1,                          # 初期再開周期
    'T_mult': 2,                       # 周期乗数
    # OneCycleLR 固有パラメータ
    'pct_start': 0.3,                  # 学習率上昇段階の割合
    # CyclicLR 固有パラメータ
    'epoch_size_up': 1,                # 半周期エポック数
    'mode': 'triangular',              # 周期モード
}
```

#### サポートされるスケジューラータイプ：
1. **ReduceLROnPlateau**：検証損失停滞時に学習率を下げる（推奨）
2. **StepLR**：固定ステップで学習率を下げる
3. **CosineAnnealingWarmRestarts**：コサインアニーリング+ウォームリスタート
4. **CosineAnnealingLR**：コサインアニーリング
5. **CyclicLR**：循環学習率
6. **OneCycleLR**：ワンサイクル学習率

#### スケジューラー選択提案：
- **小データセット**：`ReduceLROnPlateau` を推奨
- **大データセット**：`CosineAnnealingWarmRestarts` を推奨
- **高速収束**：`CyclicLR` を試行

### DEVICE_CONFIG - ハードウェア設定パラメータ

```python
DEVICE_CONFIG = {
    'use_cuda': True,                   # CUDA加速を使用するか
    'cuda_device': 0,                   # CUDAデバイスID（マルチGPU時に指定）
}
```

#### ハードウェア設定説明：
- **単一GPU**：デフォルト設定を維持
- **マルチGPU**：`cuda_device` を目標GPU IDに設定
- **CPU訓練**：`use_cuda=False` に設定（非推奨、訓練が極めて遅い）

## 設定ファイル使用例

### 基本設定（初心者推奨）
```python
# 小バッチ、保守的設定
TRAINING_CONFIG = {
    'train_batch_size': 2,
    'val_batch_size': 16,
    'epochs': 50,
    'early_stopping_patience': 5,
}

SCHEDULER_CONFIG = {
    'type': 'ReduceLROnPlateau',
    'max_lr': 1e-4,
    'plateau_patience': 3,
}
```

### 高性能設定（十分なGPUメモリ用）
```python
# 大バッチ、高速訓練
TRAINING_CONFIG = {
    'train_batch_size': 8,
    'val_batch_size': 32,
    'num_workers': 1,
    'epochs': 100,
}

SCHEDULER_CONFIG = {
    'type': 'CosineAnnealingWarmRestarts',
    'max_lr': 1e-3,
    'T_0': 10,
}
```

### デバッグ設定（フロー高速検証）
```python
# 小データ量、高速テスト
DATASET_CONFIG = {
    'train_dataset_indices': [0, 1],
    'val_dataset_indices': [2],
    'test_dataset_indices': [3],
}

TRAINING_CONFIG = {
    'epochs': 5,
    'early_stopping_patience': 1,
}
```

## 完全なワークフロー

### ステップ1：環境準備
1. 依存パッケージのインストール：
   ```bash
   pip install torch torchvision monai numpy matplotlib pandas scikit-image pytorch-msssim wandb tensorboard seaborn tqdm
   ```

2. データセット完全性チェック：
   ```bash
   python check_data.py
   ```

### ステップ2：モデル訓練
1. 訓練パラメータの設定（`config.py`）
2. 訓練スクリプトの実行：
   ```bash
   python 001_train.py
   ```
3. 訓練プロセスの監視（TensorBoardまたはW&B）

### ステップ3：モデル推論
1. 推論スクリプト内のモデルパスを更新
2. 推論実行：
   ```bash
   python 002_inference.py
   ```

### ステップ4：複数モデル比較評価
1. 複数モデルの結果パスを設定
2. 評価スクリプト実行：
   ```bash
   python 101_evaluate_multi_infer_AllSubjects.py
   ```

## 注意事項

1. **メモリ管理**：訓練と推論プロセスは大量のGPUメモリを使用するため、GPUメモリ>=8GBを推奨
2. **データフォーマット**：入力データは512x512の16ビット符号付き整数RAWフォーマットである必要があります
3. **パス設定**：全てのパスで絶対パスを使用し、相対パスによるエラーを避ける
4. **モデル互換性**：推論時に使用するモデルは訓練時のアーキテクチャと完全に一致する必要があります

## トラブルシューティング

### よくある問題
1. **メモリ不足**：バッチサイズを減らす
2. **CUDAエラー**：CUDAバージョンとPyTorchバージョンの互換性をチェック
3. **データロード失敗**：データパスとファイル権限を確認
4. **モデルロード失敗**：モデルファイルの完全性とパスの正確性を確認

### ログ確認
- TensorBoard：`tensorboard --logdir experiments/`
- コンソール出力：詳細な訓練進行状況とエラー情報を含む
- 実験設定：実験ディレクトリの `configs/` フォルダに保存

## データ構造要件

### 入力データフォーマット
- **画像サイズ**：512 × 512 ピクセル
- **データタイプ**：16ビット符号付き整数（int16）
- **ファイル拡張子**：`.img`（RAWバイナリフォーマット）

## 評価指標詳細

### 画像品質指標
- **PSNR（ピーク信号対雑音比）**
  - 計算式：20 * log10(MAX_VALUE / sqrt(MSE))
  - 典型的な良好値：> 30 dB
  - 用途：画像再構成の全体的な品質を測定

- **SSIM（構造類似性指数）**
  - 計算式：輝度、コントラスト、構造の包括的評価
  - 範囲：0-1（1が完全一致）
  - 用途：画像構造保持度の評価

- **MS-SSIM（マルチスケール SSIM）**
  - 複数の解像度レベルでSSIMを計算
  - より人間の視覚的知覚に近い
  - 画像の詳細により敏感

- **Corr2（相関係数）**
  - ピアソン相関係数
  - 範囲：-1 ～ 1（1が完全正相関）
  - 用途：画像間の線形相関性を測定

- **MAE（平均絶対誤差）**
  - 計算式：mean(|predicted - ground_truth|)
  - 単位：画像ピクセル値と同じ
  - 用途：ピクセル単位の予測精度を測定

- **RMSE（平方根平均二乗誤差）**
  - 計算式：sqrt(mean((predicted - ground_truth)²))
  - 単位：画像ピクセル値と同じ
  - 用途：大きな誤差により敏感な全体誤差測定

### 評価閾値参考
- **優秀レベル**：PSNR > 35 dB, SSIM > 0.95, Corr2 > 0.98
- **良好レベル**：PSNR > 30 dB, SSIM > 0.90, Corr2 > 0.95
- **許容レベル**：PSNR > 25 dB, SSIM > 0.85, Corr2 > 0.90