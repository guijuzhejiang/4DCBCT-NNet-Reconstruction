{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-NetåŒ»ç™‚CTç”»åƒå‡¦ç† - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "## æ¦‚è¦\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯4D-CBCTç”»åƒã®ä¼ªå½±é™¤å»ã‚’ç›®çš„ã¨ã—ãŸN-Netãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## å®Ÿè¡Œæ‰‹é †\n",
    "1. **ç’°å¢ƒæº–å‚™**: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š\n",
    "2. **å®Ÿé¨“è¨­å®š**: å†ç¾æ€§ç¢ºä¿ã¨å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "3. **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¨­å®š**: GPU/CPUä½¿ç”¨è¨­å®šã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–\n",
    "4. **ãƒ­ã‚®ãƒ³ã‚°è¨­å®š**: TensorBoardãƒ»W&Bè¨­å®š\n",
    "5. **ãƒ‡ãƒ¼ã‚¿æº–å‚™**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã¨ãƒ­ãƒ¼ãƒ€ãƒ¼è¨­å®š\n",
    "6. **ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰**: N-Netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åˆæœŸåŒ–\n",
    "7. **æœ€é©åŒ–è¨­å®š**: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ãƒ»æå¤±é–¢æ•°è¨­å®š\n",
    "8. **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ**: ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "9. **çµæœä¿å­˜**: ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨å¯è¦–åŒ–\n",
    "10. **ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾**: ãƒ¡ãƒ¢ãƒªã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "\n",
    "## æ³¨æ„äº‹é …\n",
    "- GPU ãƒ¡ãƒ¢ãƒªä¸è¶³æ™‚ã¯ batch_size ã‚’èª¿æ•´ã—ã¦ãã ã•ã„\n",
    "- AMP (Automatic Mixed Precision) ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’æ”¹å–„\n",
    "- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç‡ã¯ä½¿ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦èª¿æ•´å¯èƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒæº–å‚™ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "**ç›®çš„**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®šã¨å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ \n",
    "- åŒ»ç™‚ç”»åƒå‡¦ç†ãƒ»æ·±å±¤å­¦ç¿’é–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "- è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŠ‘åˆ¶è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®è¨­å®šã¨ç¢ºèª\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"\"))\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"../..\"))\n",
    "\n",
    "# Pythonãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ : {project_root}\")\n",
    "else:\n",
    "    print(f\"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¯æ—¢ã«Pythonãƒ‘ã‚¹ã«å­˜åœ¨: {project_root}\")\n",
    "\n",
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ç¢ºèª\n",
    "if not os.path.exists(project_root):\n",
    "    raise FileNotFoundError(f\"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {project_root}\")\n",
    "\n",
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 11:09:49.083077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-03 11:09:49.083114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-03 11:09:49.084174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-03 11:09:49.090491: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-03 11:09:50.020209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "# MONAIé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "from monai.losses import SSIMLoss, PerceptualLoss\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ToTensord\n",
    "from monai.data import CacheDataset, ThreadDataLoader\n",
    "from monai.metrics import SSIMMetric, MAEMetric, PSNRMetric, RMSEMetric\n",
    "\n",
    "# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
    "from NNet.model_Nnet import Nnet\n",
    "from NNet.Monai.TrainDataset_Nnet import Nnet_Dataset\n",
    "from NNet.config import TRAINING_CONFIG, DATASET_CONFIG, MODEL_CONFIG, LOGGING_CONFIG, SCHEDULER_CONFIG, DEVICE_CONFIG\n",
    "from NNet.utils import get_dataset_slice_counts, setup_device, save_model\n",
    "\n",
    "# è­¦å‘Šã‚’éè¡¨ç¤ºã«\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å®Ÿé¨“è¨­å®šãƒ»å†ç¾æ€§ã®ç¢ºä¿\n",
    "\n",
    "**ç›®çš„**: å®Ÿé¨“ã®å†ç¾æ€§ç¢ºä¿ã¨çµæœç®¡ç†ã®ãŸã‚ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "- **å†ç¾æ€§**: ã‚·ãƒ¼ãƒ‰å€¤ã‚’å›ºå®šã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’ä¸€è²«ã•ã›ã‚‹\n",
    "- **å®Ÿé¨“ç®¡ç†**: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿé¨“çµæœã‚’æ•´ç†\n",
    "- **è¨­å®šä¿å­˜**: å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•çš„ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦å†ç¾å¯èƒ½æ€§ã‚’ç¢ºä¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: experiments/Nnet/20250703_103903\n",
      "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ: experiments/Nnet/20250703_103903/configs\n"
     ]
    }
   ],
   "source": [
    "# å†ç¾æ€§ã®ãŸã‚ã®ã‚·ãƒ¼ãƒ‰è¨­å®š\n",
    "set_determinism(seed=42)\n",
    "\n",
    "# å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_dir = os.path.join(\"experiments\", \"Nnet\", f\"{timestamp}\")\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "print(f\"å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {experiment_dir}\")\n",
    "\n",
    "# è¨­å®šã®ä¿å­˜\n",
    "def save_configs(experiment_dir):\n",
    "    \"\"\"å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è¨­å®šã‚’ä¿å­˜\"\"\"\n",
    "    config_dir = os.path.join(experiment_dir, \"configs\")\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "    configs = {\n",
    "        \"training_config\": TRAINING_CONFIG,\n",
    "        \"dataset_config\": DATASET_CONFIG,\n",
    "        \"model_config\": MODEL_CONFIG,\n",
    "        \"logging_config\": LOGGING_CONFIG,\n",
    "        \"scheduler_config\": SCHEDULER_CONFIG,\n",
    "        \"device_config\": DEVICE_CONFIG\n",
    "    }\n",
    "    \n",
    "    for name, config in configs.items():\n",
    "        with open(os.path.join(config_dir, f\"{name}.txt\"), \"w\") as f:\n",
    "            f.write(f\"{name}:\\n\")\n",
    "            for key, value in config.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    print(f\"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ: {config_dir}\")\n",
    "\n",
    "save_configs(experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š\n",
    "ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ï¼ˆGPU/CPUï¼‰ã‚’è¨­å®šã—ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—å™¨ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "Memory: 25.4 GB\n",
      "ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š\n",
    "device = setup_device(DEVICE_CONFIG['use_cuda'], DEVICE_CONFIG['cuda_device'])\n",
    "\n",
    "# ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—å™¨ã®åˆæœŸåŒ–\n",
    "ssim_metric = SSIMMetric(spatial_dims=2, reduction=\"mean\")\n",
    "mae_metric = MAEMetric(reduction=\"mean\")\n",
    "psnr_metric = PSNRMetric(max_val=1.0, reduction=\"mean\")\n",
    "rmse_metric = RMSEMetric(reduction=\"mean\")\n",
    "\n",
    "print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š\n",
    "TensorBoardã¨Weights & Biasesã®è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoardãƒ­ã‚°ä¿å­˜å…ˆ: experiments/Nnet/20250703_103903/tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguiju\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>experiments/Nnet/20250703_103903/wandb/run-20250703_104018-h3pmeqlb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guiju/nnet-medical-ct/runs/h3pmeqlb' target=\"_blank\">20250703_103903</a></strong> to <a href='https://wandb.ai/guiju/nnet-medical-ct' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guiju/nnet-medical-ct' target=\"_blank\">https://wandb.ai/guiju/nnet-medical-ct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guiju/nnet-medical-ct/runs/h3pmeqlb' target=\"_blank\">https://wandb.ai/guiju/nnet-medical-ct/runs/h3pmeqlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Biasesãƒ­ã‚®ãƒ³ã‚°ã‚’é–‹å§‹\n"
     ]
    }
   ],
   "source": [
    "# TensorBoardè¨­å®š\n",
    "if LOGGING_CONFIG['use_tensorboard']:\n",
    "    tb_log_dir = os.path.join(experiment_dir, \"tensorboard\")\n",
    "    os.makedirs(tb_log_dir, exist_ok=True)\n",
    "    tb_writer = SummaryWriter(tb_log_dir)\n",
    "    print(f\"TensorBoardãƒ­ã‚°ä¿å­˜å…ˆ: {tb_log_dir}\")\n",
    "else:\n",
    "    tb_writer = None\n",
    "\n",
    "# Weights & Biasesè¨­å®š\n",
    "use_wandb = False\n",
    "if LOGGING_CONFIG['use_wandb']:\n",
    "    run_name = os.path.basename(experiment_dir)\n",
    "    try:\n",
    "        wandb.init(\n",
    "            project=LOGGING_CONFIG['wandb_project'],\n",
    "            entity=LOGGING_CONFIG['wandb_entity'],\n",
    "            config={\n",
    "                **TRAINING_CONFIG,\n",
    "                **DATASET_CONFIG,\n",
    "                **MODEL_CONFIG,\n",
    "                **SCHEDULER_CONFIG\n",
    "            },\n",
    "            name=run_name,\n",
    "            dir=experiment_dir\n",
    "        )\n",
    "        use_wandb = True\n",
    "        print(\"Weights & Biasesãƒ­ã‚®ãƒ³ã‚°ã‚’é–‹å§‹\")\n",
    "    except Exception as e:\n",
    "        print(f\"Weights & Biasesã®åˆæœŸåŒ–ã«å¤±æ•—: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ\n",
    "\n",
    "**ç›®çš„**: åŒ»ç™‚CTç”»åƒãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªèª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†\n",
    "- **ãƒ‡ãƒ¼ã‚¿å½¢å¼**: PNGç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆNPYå½¢å¼ã«ã‚‚å¯¾å¿œå¯èƒ½ï¼‰\n",
    "- **å‰å‡¦ç†**: ã‚¹ã‚±ãƒ¼ãƒ«æ­£è¦åŒ–ã€ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒç¢ºä¿ã€ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›\n",
    "- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è€ƒæ…®ã—ãŸéƒ¨åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ10%ï¼‰\n",
    "- **ä¸¦åˆ—å‡¦ç†**: ãƒãƒ«ãƒãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚‹é«˜é€Ÿãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "**æ³¨æ„**: NPYå½¢å¼ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ `TrainDataset_Nnet_NPY.py` ã¨ `LoadImaged(reader=\"numpyreader\")` ã‚’ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®šç¾©ï¼ˆPNGç”¨ã€NPYç”¨ã«ã‚‚å¯¾å¿œå¯èƒ½ï¼‰\n",
    "train_val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"img\", \"prior\", \"label\"]),  # NPYä½¿ç”¨æ™‚: reader=\"numpyreader\"ã‚’è¿½åŠ \n",
    "    EnsureChannelFirstd(keys=[\"img\", \"prior\", \"label\"]),  # ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒã‚’æœ€åˆã«é…ç½®\n",
    "    ScaleIntensityd(keys=[\"img\", \"prior\", \"label\"]),      # [0,1]ç¯„å›²ã«æ­£è¦åŒ–\n",
    "    ToTensord(keys=[\"img\", \"prior\", \"label\"])             # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\n",
    "])\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®çµ¶å¯¾ãƒ‘ã‚¹åŒ–\n",
    "DATASET_CONFIG['data_root'] = os.path.join(project_root, DATASET_CONFIG['data_root'])\n",
    "print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆ: {DATASET_CONFIG['data_root']}\")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
    "print(\"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...\")\n",
    "slice_counts_train = get_dataset_slice_counts(\n",
    "    DATASET_CONFIG['data_root'],\n",
    "    DATASET_CONFIG['train_dataset_indices'],\n",
    ")\n",
    "print(f\"å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {DATASET_CONFIG['train_dataset_indices']}\")\n",
    "print(f\"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ©ã‚¤ã‚¹æ•°: {slice_counts_train}\")\n",
    "\n",
    "train_dataset = Nnet_Dataset(\n",
    "    DATASET_CONFIG['data_root'],  # é™è³ªç”»åƒãƒ«ãƒ¼ãƒˆ\n",
    "    DATASET_CONFIG['data_root'],  # å…ˆé¨“ç”»åƒãƒ«ãƒ¼ãƒˆ\n",
    "    DATASET_CONFIG['data_root'],  # GTç”»åƒãƒ«ãƒ¼ãƒˆ\n",
    "    DATASET_CONFIG['train_dataset_indices'],\n",
    "    slice_counts_train,\n",
    ")\n",
    "\n",
    "# ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
    "print(\"\\nãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...\")\n",
    "slice_counts_val = get_dataset_slice_counts(\n",
    "    DATASET_CONFIG['data_root'],\n",
    "    DATASET_CONFIG['val_dataset_indices'],\n",
    ")\n",
    "print(f\"å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {DATASET_CONFIG['val_dataset_indices']}\")\n",
    "print(f\"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ©ã‚¤ã‚¹æ•°: {slice_counts_val}\")\n",
    "\n",
    "val_dataset = Nnet_Dataset(\n",
    "    DATASET_CONFIG['data_root'],\n",
    "    DATASET_CONFIG['data_root'],\n",
    "    DATASET_CONFIG['data_root'],\n",
    "    DATASET_CONFIG['val_dataset_indices'],\n",
    "    slice_counts_val,\n",
    ")\n",
    "\n",
    "# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ\n",
    "print(\"\\nã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...\")\n",
    "# åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦cache_rateã‚’èª¿æ•´å¯èƒ½ï¼ˆ0.1 = 10%ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰\n",
    "cache_rate = 0.1  \n",
    "print(f\"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç‡: {cache_rate*100}% (ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æŠ‘åˆ¶)\")\n",
    "\n",
    "train_dataset_cache = CacheDataset(\n",
    "    data=train_dataset.samples,\n",
    "    transform=train_val_transforms,\n",
    "    cache_rate=cache_rate,\n",
    "    num_workers=4,       # ä¸¦åˆ—å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°\n",
    "    progress=True        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º\n",
    ")\n",
    "\n",
    "val_dataset_cache = CacheDataset(\n",
    "    data=val_dataset.samples,\n",
    "    transform=train_val_transforms,\n",
    "    cache_rate=cache_rate,\n",
    "    num_workers=2,\n",
    "    progress=True\n",
    ")\n",
    "\n",
    "# é«˜åŠ¹ç‡ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ\n",
    "print(\"\\nãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆä¸­...\")\n",
    "train_loader = ThreadDataLoader(\n",
    "    train_dataset_cache,\n",
    "    batch_size=TRAINING_CONFIG['train_batch_size'],\n",
    "    shuffle=True,                    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«\n",
    "    num_workers=TRAINING_CONFIG['num_workers'],\n",
    "    drop_last=False,                 # æœ€å¾Œã®ä¸å®Œå…¨ãƒãƒƒãƒã‚‚ä½¿ç”¨\n",
    "    pin_memory=torch.cuda.is_available(),  # CUDAä½¿ç”¨æ™‚ã¯ãƒ¡ãƒ¢ãƒªå›ºå®š\n",
    "    prefetch_factor=2,               # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º\n",
    "    persistent_workers=True          # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹æ°¸ç¶šåŒ–\n",
    ")\n",
    "\n",
    "val_loader = ThreadDataLoader(\n",
    "    val_dataset_cache,\n",
    "    batch_size=TRAINING_CONFIG['val_batch_size'],\n",
    "    num_workers=TRAINING_CONFIG['num_workers'],\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ:\")\n",
    "print(f\"  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(train_dataset_cache):,}\")\n",
    "print(f\"  ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(val_dataset_cache):,}\")\n",
    "print(f\"  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒƒãƒæ•°: {len(train_loader)}\")\n",
    "print(f\"  ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒæ•°: {len(val_loader)}\")\n",
    "print(f\"  ãƒãƒƒãƒã‚µã‚¤ã‚º (train/val): {TRAINING_CONFIG['train_batch_size']}/{TRAINING_CONFIG['val_batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰\n",
    "N-netãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-Netãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨ãƒ‡ãƒã‚¤ã‚¹é…ç½®\n",
    "print(\"N-Netãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...\")\n",
    "model = Nnet()\n",
    "model = model.to(device)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ç¢ºèª\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ğŸ“‹ ãƒ¢ãƒ‡ãƒ«æƒ…å ±:\")\n",
    "print(f\"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}\")\n",
    "print(f\"  è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}\")\n",
    "print(f\"  ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: {total_params * 4 / 1024**2:.1f} MB (float32)\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©³ç´°è¡¨ç¤º\n",
    "print(\"\\nğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°:\")\n",
    "try:\n",
    "    summary(model, [\n",
    "        (MODEL_CONFIG['input_channels'], *DATASET_CONFIG['image_size']),  # é™è³ªç”»åƒå…¥åŠ›\n",
    "        (MODEL_CONFIG['input_channels'], *DATASET_CONFIG['image_size'])   # å…ˆé¨“ç”»åƒå…¥åŠ›\n",
    "    ])\n",
    "except Exception as e:\n",
    "    print(f\"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "    print(\"ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®ç°¡ç•¥è¡¨ç¤º:\")\n",
    "    print(model)\n",
    "\n",
    "# TensorBoardã¸ã®ãƒ¢ãƒ‡ãƒ«ã‚°ãƒ©ãƒ•è¿½åŠ ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰\n",
    "if tb_writer:\n",
    "    try:\n",
    "        print(\"\\nğŸ“Š TensorBoardã«ãƒ¢ãƒ‡ãƒ«ã‚°ãƒ©ãƒ•ã‚’è¿½åŠ ä¸­...\")\n",
    "        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ã®ä½œæˆï¼ˆå…¥åŠ›ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ï¼‰\n",
    "        dummy_input1 = torch.randn(\n",
    "            1, MODEL_CONFIG['input_channels'], *DATASET_CONFIG['image_size']\n",
    "        ).to(device)\n",
    "        dummy_input2 = torch.randn(\n",
    "            1, MODEL_CONFIG['input_channels'], *DATASET_CONFIG['image_size']\n",
    "        ).to(device)\n",
    "        \n",
    "        # ãƒ¢ãƒ‡ãƒ«ã‚°ãƒ©ãƒ•ã‚’TensorBoardã«è¿½åŠ \n",
    "        tb_writer.add_graph(model, (dummy_input1, dummy_input2))\n",
    "        print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚°ãƒ©ãƒ•ã‚’TensorBoardã«æ­£å¸¸ã«è¿½åŠ \")\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªè§£æ”¾\n",
    "        del dummy_input1, dummy_input2\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ TensorBoardã‚°ãƒ©ãƒ•è¿½åŠ ã«å¤±æ•—: {str(e)}\")\n",
    "\n",
    "print(\"\\nâœ… ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨æå¤±é–¢æ•°ã®è¨­å®š\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã€æå¤±é–¢æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šã®è¨ˆç®—ã¨è¡¨ç¤º\n",
    "batches_per_epoch = len(train_loader)\n",
    "total_batches = TRAINING_CONFIG['epochs'] * batches_per_epoch\n",
    "print(f\"ğŸ“ˆ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š:\")\n",
    "print(f\"  ã‚¨ãƒãƒƒã‚¯æ•°: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"  ãƒãƒƒãƒæ•°/ã‚¨ãƒãƒƒã‚¯: {batches_per_epoch}\")\n",
    "print(f\"  ç·ãƒãƒƒãƒæ•°: {total_batches:,}\")\n",
    "\n",
    "# Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®è¨­å®š\n",
    "print(f\"\\nâš™ï¸ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š:\")\n",
    "print(f\"  ç¨®é¡: Adam\")\n",
    "print(f\"  åˆæœŸå­¦ç¿’ç‡: {SCHEDULER_CONFIG['max_lr']}\")\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=SCHEDULER_CONFIG['max_lr'],\n",
    "    betas=(0.9, 0.999),           # Adam momentum parameters\n",
    "    eps=1e-8,                     # numerical stability\n",
    "    weight_decay=0                # L2æ­£å‰‡åŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´ï¼‰\n",
    ")\n",
    "\n",
    "# ã‚³ã‚µã‚¤ãƒ³å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®š\n",
    "print(f\"\\nğŸ“‰ å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š:\")\n",
    "print(f\"  ç¨®é¡: CosineAnnealingLR\")\n",
    "print(f\"  æœ€å¤§å­¦ç¿’ç‡: {SCHEDULER_CONFIG['max_lr']}\")\n",
    "print(f\"  æœ€å°å­¦ç¿’ç‡: {SCHEDULER_CONFIG['min_lr']}\")\n",
    "print(f\"  ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_batches:,}\")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_batches,          # å…¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—æ•°\n",
    "    eta_min=SCHEDULER_CONFIG['min_lr'],  # æœ€å°å­¦ç¿’ç‡\n",
    "    last_epoch=-1                 # åˆæœŸå€¤\n",
    ")\n",
    "\n",
    "# åŒ»ç™‚ç”»åƒå°‚ç”¨æå¤±é–¢æ•°ã®è¨­å®š\n",
    "print(f\"\\nğŸ¯ æå¤±é–¢æ•°è¨­å®š:\")\n",
    "print(f\"  è¤‡åˆæå¤±é–¢æ•°ï¼ˆ4ã¤ã®æå¤±ã®é‡ã¿ä»˜ãçµ„ã¿åˆã‚ã›ï¼‰\")\n",
    "\n",
    "# å„æå¤±é–¢æ•°ã®åˆæœŸåŒ–\n",
    "mse_loss = MSELoss().to(device)\n",
    "l1_loss = L1Loss().to(device)\n",
    "ssim_loss = SSIMLoss(spatial_dims=2).to(device)\n",
    "perceptual_loss = PerceptualLoss(spatial_dims=2, network_type=\"alex\").to(device)\n",
    "\n",
    "# æå¤±é‡ã¿ã®è¨­å®šï¼ˆconfig.pyã‹ã‚‰å–å¾—ï¼‰\n",
    "loss_weights = {\n",
    "    'mse': TRAINING_CONFIG['weight_mse'],       # ç”»åƒå†æ§‹ç¯‰ã®åŸºæœ¬æå¤±\n",
    "    'l1': TRAINING_CONFIG['weight_l1'],         # ã‚¨ãƒƒã‚¸ä¿æŒã®ãŸã‚ã®L1æå¤±\n",
    "    'ssim': TRAINING_CONFIG['weight_ssim'],     # æ§‹é€ é¡ä¼¼æ€§æå¤±\n",
    "    'perceptual': TRAINING_CONFIG['weight_percep']  # çŸ¥è¦šçš„æå¤±\n",
    "}\n",
    "\n",
    "print(f\"  æå¤±é‡ã¿: MSE={loss_weights['mse']}, L1={loss_weights['l1']}, SSIM={loss_weights['ssim']}, Perceptual={loss_weights['perceptual']}\")\n",
    "\n",
    "# åŒ»ç™‚ç”»åƒç‰¹åŒ–ã®è¤‡åˆæå¤±é–¢æ•°\n",
    "def combined_loss(pred, target):\n",
    "    \"\"\"\n",
    "    4ã¤ã®æå¤±é–¢æ•°ã‚’çµ„ã¿åˆã‚ã›ãŸåŒ»ç™‚ç”»åƒå°‚ç”¨æå¤±\n",
    "    \n",
    "    Args:\n",
    "        pred: ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬çµæœ [B, C, H, W]\n",
    "        target: æ­£è§£ç”»åƒ [B, C, H, W]\n",
    "    \n",
    "    Returns:\n",
    "        combined_loss: é‡ã¿ä»˜ãæå¤±ã®åˆè¨ˆ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # å„æå¤±ã®è¨ˆç®—\n",
    "        mse = mse_loss(pred, target)          # Mean Squared Error\n",
    "        l1 = l1_loss(pred, target)            # L1 Loss (MAE)\n",
    "        ssim = ssim_loss(pred, target)        # Structural Similarity\n",
    "        percep = perceptual_loss(pred, target) # Perceptual Loss\n",
    "        \n",
    "        # é‡ã¿ä»˜ãã§çµ„ã¿åˆã‚ã›\n",
    "        total_loss = (loss_weights['mse'] * mse + \n",
    "                     loss_weights['l1'] * l1 + \n",
    "                     loss_weights['perceptual'] * percep + \n",
    "                     loss_weights['ssim'] * ssim)\n",
    "        \n",
    "        return total_loss\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"æå¤±è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: MSEæå¤±ã®ã¿\n",
    "        return mse_loss(pred, target)\n",
    "\n",
    "print(f\"\\nâœ… æœ€é©åŒ–è¨­å®šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°\n",
    "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, target):\n",
    "    \"\"\"\n",
    "    åŒ»ç™‚ç”»åƒè©•ä¾¡æŒ‡æ¨™ã®åŠ¹ç‡çš„ãªè¨ˆç®—\n",
    "    \n",
    "    åŒ»ç™‚ç”»åƒã®å“è³ªè©•ä¾¡ã«é‡è¦ãª4ã¤ã®æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã¾ã™ï¼š\n",
    "    - RMSE: æ ¹å¹³å‡äºŒä¹—èª¤å·®ï¼ˆç”»ç´ ãƒ¬ãƒ™ãƒ«ã®å†æ§‹ç¯‰ç²¾åº¦ï¼‰\n",
    "    - MAE: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆå¹³å‡çš„ãªç”»ç´ å·®ï¼‰\n",
    "    - PSNR: ãƒ”ãƒ¼ã‚¯ä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼ˆç”»åƒå“è³ªã®å®¢è¦³è©•ä¾¡ï¼‰\n",
    "    - SSIM: æ§‹é€ é¡ä¼¼æ€§æŒ‡æ•°ï¼ˆäººé–“ã®è¦–è¦šçš„èªè­˜ã«è¿‘ã„è©•ä¾¡ï¼‰\n",
    "    \n",
    "    Args:\n",
    "        pred: ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬çµæœ [B, C, H, W]\n",
    "        target: æ­£è§£ç”»åƒ [B, C, H, W]\n",
    "    \n",
    "    Returns:\n",
    "        dict: å„è©•ä¾¡æŒ‡æ¨™ã®å€¤ã‚’å«ã‚€è¾æ›¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ãƒ‡ãƒ¼ã‚¿å‹ã®çµ±ä¸€ï¼ˆè¨ˆç®—ç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰\n",
    "        pred = pred.float()\n",
    "        target = target.float()\n",
    "        \n",
    "        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚»ãƒƒãƒˆï¼ˆMONAIç‰¹æœ‰ã®è¦ä»¶ï¼‰\n",
    "        ssim_metric.reset()\n",
    "        mae_metric.reset()\n",
    "        psnr_metric.reset()\n",
    "        rmse_metric.reset()\n",
    "        \n",
    "        # ãƒãƒƒãƒå˜ä½ã§ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—\n",
    "        # SSIM: æ§‹é€ é¡ä¼¼æ€§ï¼ˆ-1ã€œ1ã€1ãŒæœ€è‰¯ï¼‰\n",
    "        ssim_metric(pred, target)\n",
    "        ssim_val = ssim_metric.aggregate().item()\n",
    "        \n",
    "        # MAE: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆ0ãŒæœ€è‰¯ï¼‰\n",
    "        mae_metric(pred, target)\n",
    "        mae_val = mae_metric.aggregate().item()\n",
    "        \n",
    "        # PSNR: ãƒ”ãƒ¼ã‚¯ä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼ˆé«˜ã„ã»ã©è‰¯ã„ã€é€šå¸¸20-50dBï¼‰\n",
    "        psnr_metric(pred, target)\n",
    "        psnr_val = psnr_metric.aggregate().item()\n",
    "        \n",
    "        # RMSE: æ ¹å¹³å‡äºŒä¹—èª¤å·®ï¼ˆ0ãŒæœ€è‰¯ï¼‰\n",
    "        rmse_metric(pred, target)\n",
    "        rmse_val = rmse_metric.aggregate().item()\n",
    "        \n",
    "        return {\n",
    "            \"rmse\": rmse_val,\n",
    "            \"mae\": mae_val,\n",
    "            \"psnr\": psnr_val,\n",
    "            \"ssim\": ssim_val\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤\n",
    "        return {\n",
    "            \"rmse\": float('inf'),\n",
    "            \"mae\": float('inf'),\n",
    "            \"psnr\": 0.0,\n",
    "            \"ssim\": 0.0\n",
    "        }\n",
    "\n",
    "def format_metrics_string(metrics_dict, precision=6):\n",
    "    \"\"\"\n",
    "    ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾æ›¸ã‚’è¦‹ã‚„ã™ã„æ–‡å­—åˆ—ã«å¤‰æ›\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: calculate_metricsã®è¿”ã‚Šå€¤\n",
    "        precision: å°æ•°ç‚¹ä»¥ä¸‹ã®æ¡æ•°\n",
    "    \n",
    "    Returns:\n",
    "        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ–‡å­—åˆ—\n",
    "    \"\"\"\n",
    "    return (f\"RMSE: {metrics_dict['rmse']:.{precision}f}, \"\n",
    "            f\"MAE: {metrics_dict['mae']:.{precision}f}, \"\n",
    "            f\"PSNR: {metrics_dict['psnr']:.{precision}f}dB, \"\n",
    "            f\"SSIM: {metrics_dict['ssim']:.{precision}f}\")\n",
    "\n",
    "print(\"âœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°ã‚’å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ\n",
    "\n",
    "**ç›®çš„**: N-Netãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "- **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°**: ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã€å‹¾é…æœ€é©åŒ–\n",
    "- **ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**: éå­¦ç¿’ç›£è¦–ã¨ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "- **ãƒ­ã‚°è¨˜éŒ²**: TensorBoardãƒ»W&Bã§ã®è©³ç´°ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡\n",
    "- **ãƒ¡ãƒ¢ãƒªç®¡ç†**: OOMå¯¾å¿œã¨GPUãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–\n",
    "- **é€²æ—è¡¨ç¤º**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®å­¦ç¿’çŠ¶æ³å¯è¦–åŒ–\n",
    "\n",
    "**é‡è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:\n",
    "- å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°: `max_norm=1.0` ï¼ˆå‹¾é…çˆ†ç™ºé˜²æ­¢ï¼‰\n",
    "- ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º: 10ãƒãƒƒãƒã”ã¨ï¼ˆè¨ˆç®—åŠ¹ç‡ã¨ãƒ­ã‚°è©³ç´°åº¦ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰\n",
    "- ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æå¤±æœ€å°æ™‚ã«è‡ªå‹•ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...\n",
      "\n",
      "ã‚¨ãƒãƒƒã‚¯ 1/40\n",
      "--------------------------------------------------\n",
      "[ã‚¨ãƒãƒƒã‚¯ 1] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m batch_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# é€²æ—è¡¨ç¤º\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# 10ãƒãƒƒãƒã”ã¨ã«è¡¨ç¤º\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(pred, target)\u001b[0m\n\u001b[1;32m     11\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mssim_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m ssim_val \u001b[38;5;241m=\u001b[39m ssim_metric\u001b[38;5;241m.\u001b[39maggregate()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m mae_metric(pred, target)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/metrics/metric.py:347\u001b[0m, in \u001b[0;36mCumulativeIterationMetric.__call__\u001b[0;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m, y_pred: TensorOrList, y: TensorOrList \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m Sequence[torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m Sequence[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m    Execute basic computation for model prediction and ground truth.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    It can support  both `list of channel-first Tensor` and `batch-first Tensor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m        a `batch-first` tensor (BC[HWD]) or a list of `batch-first` tensors.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;241m*\u001b[39mret)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/metrics/metric.py:80\u001b[0m, in \u001b[0;36mIterationMetric.__call__\u001b[0;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_pred, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     79\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred or y must be a list/tuple of `channel-first` Tensors or a `batch-first` Tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/metrics/regression.py:85\u001b[0m, in \u001b[0;36mRegressionMetric._compute_tensor\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred and y must be PyTorch Tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_shape(y_pred, y)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/metrics/regression.py:310\u001b[0m, in \u001b[0;36mSSIMMetric._compute_metric\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_dims \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dims \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred should have 5 dimensions (batch, channel, height, width, depth) when using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m spatial dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m ssim_value_full_image, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ssim_and_cs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspatial_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m ssim_per_batch: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m ssim_value_full_image\u001b[38;5;241m.\u001b[39mview(ssim_value_full_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    324\u001b[0m )\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssim_per_batch\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/metrics/regression.py:412\u001b[0m, in \u001b[0;36mcompute_ssim_and_cs\u001b[0;34m(y_pred, y, spatial_dims, kernel_size, kernel_sigma, data_range, kernel_type, k1, k2)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kernel_type \u001b[38;5;241m==\u001b[39m KernelType\u001b[38;5;241m.\u001b[39mUNIFORM:\n\u001b[1;32m    410\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((num_channels, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mkernel_size)) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mprod(torch\u001b[38;5;241m.\u001b[39mtensor(kernel_size))\n\u001b[0;32m--> 412\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_dst_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    414\u001b[0m c1 \u001b[38;5;241m=\u001b[39m (k1 \u001b[38;5;241m*\u001b[39m data_range) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# stability constant for luminance\u001b[39;00m\n\u001b[1;32m    415\u001b[0m c2 \u001b[38;5;241m=\u001b[39m (k2 \u001b[38;5;241m*\u001b[39m data_range) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# stability constant for contrast\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/utils/type_conversion.py:388\u001b[0m, in \u001b[0;36mconvert_to_dst_type\u001b[0;34m(src, dst, dtype, wrap_sequence, device, safe)\u001b[0m\n\u001b[1;32m    386\u001b[0m     output_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(dst)\n\u001b[1;32m    387\u001b[0m output: NdarrayTensor\n\u001b[0;32m--> 388\u001b[0m output, _type, _device \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_data_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrap_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrap_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, monai\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mMetaTensor):\n\u001b[1;32m    392\u001b[0m     output\u001b[38;5;241m.\u001b[39mcopy_meta_from(dst)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/utils/type_conversion.py:330\u001b[0m, in \u001b[0;36mconvert_data_type\u001b[0;34m(data, output_type, device, dtype, wrap_sequence, safe)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(output_type, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    329\u001b[0m     track_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28missubclass\u001b[39m(output_type, monai\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mMetaTensor)\n\u001b[0;32m--> 330\u001b[0m     data_ \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrap_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrap_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_, orig_type, orig_device\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(output_type, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_DL_cu118/lib/python3.10/site-packages/monai/utils/type_conversion.py:160\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(data, dtype, device, wrap_sequence, track_meta, safe)\u001b[0m\n\u001b[1;32m    158\u001b[0m dtype \u001b[38;5;241m=\u001b[39m get_equivalent_dtype(dtype, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# skip array of string classes and object, refer to:\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/blob/v1.9.0/torch/utils/data/_utils/collate.py#L13\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SaUO]\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;66;03m# numpy array with 0 dims is also sequence iterable,\u001b[39;00m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# `ascontiguousarray` will add 1 dim if img has no dim, so we only apply on data with dims\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è¿½è·¡å¤‰æ•°\n",
    "best_val_loss = float('inf')\n",
    "best_val_metrics = None\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "\n",
    "for epoch in range(TRAINING_CONFIG['epochs']):\n",
    "    print(f\"\\nã‚¨ãƒãƒƒã‚¯ {epoch + 1}/{TRAINING_CONFIG['epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # --- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚§ãƒ¼ã‚º ---\n",
    "    model.train()\n",
    "    print(f\"[ã‚¨ãƒãƒƒã‚¯ {epoch + 1}] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­\")\n",
    "    \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•\n",
    "        images = batch[\"img\"].to(device)\n",
    "        prior = batch[\"prior\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        \n",
    "        # å‹¾é…ã®ãƒªã‚»ãƒƒãƒˆ\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\n",
    "            prediction = model(images, prior)\n",
    "            loss = combined_loss(prediction, labels)\n",
    "            \n",
    "            # ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—\n",
    "            batch_metrics = calculate_metrics(prediction, labels)\n",
    "            \n",
    "            # é€²æ—è¡¨ç¤º\n",
    "            if (i + 1) % 10 == 0:  # 10ãƒãƒƒãƒã”ã¨ã«è¡¨ç¤º\n",
    "                print(f\"[ã‚¨ãƒãƒƒã‚¯ {epoch+1} ãƒãƒƒãƒ {i+1}] æå¤±: {loss.item():.6f}, \"\n",
    "                      f\"RMSE: {batch_metrics['rmse']:.6f}, MAE: {batch_metrics['mae']:.6f}\")\n",
    "            \n",
    "            # TensorBoardãƒ­ã‚®ãƒ³ã‚°\n",
    "            if tb_writer:\n",
    "                global_step = epoch * len(train_loader) + i\n",
    "                tb_writer.add_scalar('Train/Loss', loss.item(), global_step)\n",
    "                tb_writer.add_scalar('Train/RMSE', batch_metrics['rmse'], global_step)\n",
    "                tb_writer.add_scalar('Train/MAE', batch_metrics['mae'], global_step)\n",
    "                tb_writer.add_scalar('Train/PSNR', batch_metrics['psnr'], global_step)\n",
    "                tb_writer.add_scalar('Train/SSIM', batch_metrics['ssim'], global_step)\n",
    "            \n",
    "            # Weights & Biasesãƒ­ã‚®ãƒ³ã‚°\n",
    "            if use_wandb:\n",
    "                wandb.log({\n",
    "                    'train_loss': loss.item(),\n",
    "                    'train_rmse': batch_metrics['rmse'],\n",
    "                    'train_mae': batch_metrics['mae'],\n",
    "                    'train_psnr': batch_metrics['psnr'],\n",
    "                    'train_ssim': batch_metrics['ssim'],\n",
    "                    'epoch': epoch + 1\n",
    "                })\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(\"è­¦å‘Š: ãƒ¡ãƒ¢ãƒªä¸è¶³ - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦ç¶™ç¶š\")\n",
    "                optimizer.zero_grad()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "    \n",
    "    # --- ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚§ãƒ¼ã‚º ---\n",
    "    model.eval()\n",
    "    print(f\"[ã‚¨ãƒãƒƒã‚¯ {epoch + 1}] ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä¸­\")\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_metrics = {'rmse': 0.0, 'mae': 0.0, 'psnr': 0.0, 'ssim': 0.0}\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch[\"img\"].to(device)\n",
    "            prior = batch[\"prior\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            \n",
    "            # äºˆæ¸¬ã¨æå¤±è¨ˆç®—\n",
    "            prediction = model(images, prior)\n",
    "            loss = combined_loss(prediction, labels)\n",
    "            \n",
    "            # æå¤±ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è“„ç©\n",
    "            running_loss += loss.item()\n",
    "            batch_metrics = calculate_metrics(prediction, labels)\n",
    "            \n",
    "            for key in running_metrics:\n",
    "                running_metrics[key] += batch_metrics[key]\n",
    "            \n",
    "            num_batches += 1\n",
    "    \n",
    "    # å¹³å‡å€¤ã®è¨ˆç®—\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_metrics = {k: v / num_batches for k, v in running_metrics.items()}\n",
    "    \n",
    "    # çµæœè¡¨ç¤º\n",
    "    print(f\"[ã‚¨ãƒãƒƒã‚¯ {epoch + 1}] æ¤œè¨¼æå¤±: {avg_loss:.6f}, \"\n",
    "          f\"RMSE: {avg_metrics['rmse']:.6f}, MAE: {avg_metrics['mae']:.6f}, \"\n",
    "          f\"PSNR: {avg_metrics['psnr']:.6f}, SSIM: {avg_metrics['ssim']:.6f}\")\n",
    "    \n",
    "    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ã¨ä¿å­˜\n",
    "    if avg_loss < best_val_loss:\n",
    "        best_val_loss = avg_loss\n",
    "        best_val_metrics = avg_metrics\n",
    "        best_epoch = epoch + 1\n",
    "        \n",
    "        model_save_dir = os.path.join(experiment_dir, TRAINING_CONFIG['model_save_dir'])\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        \n",
    "        save_model(\n",
    "            model,\n",
    "            epoch + 1,\n",
    "            avg_loss,\n",
    "            model_save_dir,\n",
    "            'nnet_medical_ct_best'\n",
    "        )\n",
    "        print(f\"ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ã‚¨ãƒãƒƒã‚¯ {epoch+1} ã§ä¿å­˜\")\n",
    "    \n",
    "    # ãƒ™ã‚¹ãƒˆçµæœã®è¡¨ç¤º\n",
    "    print(f\"[ãƒ™ã‚¹ãƒˆæ¤œè¨¼çµæœ] ã‚¨ãƒãƒƒã‚¯: {best_epoch}, æå¤±: {best_val_loss:.6f}, \"\n",
    "          f\"RMSE: {best_val_metrics['rmse']:.6f}, MAE: {best_val_metrics['mae']:.6f}\")\n",
    "    \n",
    "    # TensorBoardãƒ­ã‚®ãƒ³ã‚°\n",
    "    if tb_writer:\n",
    "        tb_writer.add_scalar('Val/Loss', avg_loss, epoch)\n",
    "        tb_writer.add_scalar('Val/RMSE', avg_metrics['rmse'], epoch)\n",
    "        tb_writer.add_scalar('Val/MAE', avg_metrics['mae'], epoch)\n",
    "        tb_writer.add_scalar('Val/PSNR', avg_metrics['psnr'], epoch)\n",
    "        tb_writer.add_scalar('Val/SSIM', avg_metrics['ssim'], epoch)\n",
    "        tb_writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ç”»åƒå¯è¦–åŒ–\n",
    "        if epoch > 5 and avg_loss == best_val_loss:\n",
    "            img_cpu = images[0].cpu().float()\n",
    "            prior_cpu = prior[0].cpu().float()\n",
    "            label_cpu = labels[0].cpu().float()\n",
    "            pred_cpu = prediction[0].cpu().float()\n",
    "            \n",
    "            grid = torchvision.utils.make_grid(\n",
    "                [img_cpu, prior_cpu, label_cpu, pred_cpu],\n",
    "                nrow=4,\n",
    "                normalize=True\n",
    "            )\n",
    "            tb_writer.add_image(f\"Validation/Artifact_Removal\", grid, epoch)\n",
    "    \n",
    "    # Weights & Biasesãƒ­ã‚®ãƒ³ã‚°\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            'val_loss': avg_loss,\n",
    "            'val_rmse': avg_metrics['rmse'],\n",
    "            'val_mae': avg_metrics['mae'],\n",
    "            'val_psnr': avg_metrics['psnr'],\n",
    "            'val_ssim': avg_metrics['ssim'],\n",
    "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'epoch': epoch + 1\n",
    "        })\n",
    "\n",
    "print(\"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ãƒ»ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾\n",
    "\n",
    "**ç›®çš„**: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†å¾Œã®é©åˆ‡ãªãƒªã‚½ãƒ¼ã‚¹ç®¡ç†\n",
    "- **ãƒ­ã‚®ãƒ³ã‚°çµ‚äº†**: TensorBoardãƒ»W&Bã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ­£å¸¸çµ‚äº†\n",
    "- **ãƒ¡ãƒ¢ãƒªè§£æ”¾**: GPUãƒ»CPUãƒ¡ãƒ¢ãƒªã®åŠ¹ç‡çš„ãªè§£æ”¾\n",
    "- **çµæœä¿å­˜**: æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã¨å®Ÿé¨“ãƒ­ã‚°ã®ç¢ºèª\n",
    "\n",
    "**é‡è¦**: å®Ÿé¨“çµæœã¯ `experiment_dir` ã«è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã™\n",
    "- ãƒ¢ãƒ‡ãƒ«é‡ã¿: `trained_model/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "- TensorBoard: `tensorboard/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª  \n",
    "- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: `configs/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "- W&Bãƒ­ã‚°: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèªå¯èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§¹ ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œä¸­...\")\n",
    "\n",
    "# TensorBoardãƒ©ã‚¤ã‚¿ãƒ¼ã®å®‰å…¨ãªçµ‚äº†\n",
    "if tb_writer:\n",
    "    try:\n",
    "        tb_writer.close()\n",
    "        print(\"âœ… TensorBoardãƒ©ã‚¤ã‚¿ãƒ¼ã‚’æ­£å¸¸ã«çµ‚äº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ TensorBoardçµ‚äº†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ TensorBoardã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "\n",
    "# Weights & Biasesã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ‚äº†\n",
    "if use_wandb:\n",
    "    try:\n",
    "        wandb.finish()\n",
    "        print(\"âœ… Weights & Biasesã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ­£å¸¸ã«çµ‚äº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ W&Bçµ‚äº†ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Weights & Biasesã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "\n",
    "# GPUãƒ¡ãƒ¢ãƒªã®è§£æ”¾\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # GPUä½¿ç”¨é‡ã®è¡¨ç¤º\n",
    "        gpu_memory_used = torch.cuda.memory_allocated(device) / 1024**3  # GB\n",
    "        gpu_memory_cached = torch.cuda.memory_reserved(device) / 1024**3  # GB\n",
    "        \n",
    "        print(f\"âœ… GPUãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾å®Œäº†\")\n",
    "        print(f\"  ç¾åœ¨ã®ä½¿ç”¨é‡: {gpu_memory_used:.2f} GB\")\n",
    "        print(f\"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿: {gpu_memory_cached:.2f} GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPUãƒ¡ãƒ¢ãƒªè§£æ”¾ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ GPUã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "\n",
    "# å®Ÿé¨“çµæœã®ç¢ºèªã¨ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
    "print(f\"\\nğŸ“ å®Ÿé¨“çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {experiment_dir}\")\n",
    "print(f\"ğŸ“‹ å®Ÿé¨“ã‚µãƒãƒªãƒ¼:\")\n",
    "\n",
    "try:\n",
    "    # ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
    "    if os.path.exists(experiment_dir):\n",
    "        subdirs = ['tensorboard', 'configs', 'trained_model']\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(experiment_dir, subdir)\n",
    "            if os.path.exists(subdir_path):\n",
    "                file_count = len([f for f in os.listdir(subdir_path) \n",
    "                                if os.path.isfile(os.path.join(subdir_path, f))])\n",
    "                print(f\"  {subdir}/: {file_count} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "            else:\n",
    "                print(f\"  {subdir}/: ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "                \n",
    "        print(f\"\\nğŸ‰ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼\")\n",
    "        print(f\"ğŸ“Š TensorBoardè¡¨ç¤º: tensorboard --logdir {os.path.join(experiment_dir, 'tensorboard')}\")\n",
    "        \n",
    "        if use_wandb:\n",
    "            print(f\"ğŸŒ W&Bãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: https://wandb.ai/{LOGGING_CONFIG.get('wandb_entity', 'your-entity')}/{LOGGING_CONFIG.get('wandb_project', 'your-project')}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "\n",
    "print(f\"\\nâœ¨ å…¨ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
